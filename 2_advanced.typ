#import "@preview/touying:0.6.1": *
#import themes.university: *

#import "@preview/numbly:0.1.0": numbly

// #set text(font: "Fira Sans")
// #show math.equation: set text(font: "Fira Math")

#show: university-theme.with(config-info(
  title: [Advanced automatic differentiation],
  subtitle: [Optimization-Augmented Machine Learning:#linebreak()Theory and Practice],
  author: [Guillaume Dalle],
  date: [2025-07-22],
  institution: [LVMT, ENPC],
))

#title-slide()

#components.adaptive-columns(outline(depth: 1))

= Motivation

== Bilevel optimization

#lorem(20)

== Hybrid pipelines

#lorem(20)

= Special cases

== Max (Danskin)

#lorem(20)

== Branching (sigmoid)

#lorem(20)

== Choosing (softmax)

#lorem(20)

= Stochastic programs

== Parametric expectations

#lorem(20)

== Score function estimator

#lorem(20)

== Reparametrization

#lorem(20)

== Discrete randomness

#lorem(20)

= Continuous optimization

== Unrolling

#lorem(20)

== Implicit function theorem

#lorem(20)

== Implicit layers

#lorem(20)

== KKT conditions

#lorem(20)

== Quadratic programs

#lorem(20)

== Conic programs

#lorem(20)

== Frank-Wolfe

#lorem(20)

= Discrete optimization

== Linear programs

#lorem(20)

== Regularization

#lorem(20)

== Perturbation

#lorem(20)

= Game equilibria

== Variational inequalities

#lorem(20)

== Fixed points

#lorem(20)

= Neural surrogates

== Graph neural networks

#lorem(20)

== Dynamic programming

#lorem(20)

== Large language models

#lorem(20)

= Implementations

== Python

#lorem(20)

== Julia

#lorem(20)
